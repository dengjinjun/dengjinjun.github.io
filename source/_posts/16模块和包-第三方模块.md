---
title: 模块和包-第三方模块
date: 2023-08-15 22:39:36
tags: python
---



# 模块和包-第三方模块

## request模块

`request`模块是一个重要的第三方模块，可以让我们通过代码向某些地址发送网络请求，然后我们就可以获取到结果。

### 抓包

- 查看网络请求，空白处右键——检查——网络
  - 查看地址：`url`
  - 请求的方式
  - 传递的数据：response

- 通过代码伪造浏览器

  ```python
  import request
  
  # 原始文本
  res = request.get(
  	url = "xxxx"
      headers = {
          "User-Agent":"xxxx"
      }
  )
  
  # 解码1
  res.encoding = "utf-8"
  print(res.text)
  # 解码2
  res.content.decode("utf-8")
  
  # JSON格式
  print(json.loads(res.text))
  
  # JSONP格式：切片后转为JSON格式
  
  # HTML格式，需要安装第三方模块进行处理 pip install beautifulsoup4
  ```
  
  ## BeautifulSoup4模块
  
  `BeautifulSoup4`模块专门用于帮助我们在HTML格式的字符串中提取我们想要的数据
  
  ```python
  from bs4 import BeautifulSoup
  
  data = """<meta charset="utf-8"/>
  <meta content="webkit" name="renderer">
  <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible"/>
  <meta content="width=1400" name="viewport">
  <title>常州大学</title>
  <meta content="常州大学" name="keywords"/>
  <meta content="常州大学" name="description"/>"""
  
  
  soup_object = BeautifulSoup(data,"html.parser")		# 得到一个可解析的对象
  # 寻找一个符合特点的对象
  soup_object.find(name = "xxx",attrs = {"id": "xxx","class": "xxx"})	
  # 寻找具有共同特点的全部对象
  soup_object.find_all(name = "xxx",attrs = {"id": "xxx","class": "xxx"})	
  # 得到一个标签之后，可以获取它的全部属性
  res.text	# 文本值
  res.attrs["src"]
  res.attrs["name"]
  ```
  
  ## 一个抓取联通网上商城商品信息的案例
  
  ```python
  import requests
  from bs4 import BeautifulSoup as bs
  import re
  import os
  
  FILE_PATH = "picture"
  
  def download(url, file_path):
      pic = requests.get(url=url)
      # 2.保存到本地
      if pic:
          with open(file_path, mode="wb") as f:
              f.write(pic.content)
  
  def run():
      # 创建文件
      if not os.path.exists(FILE_PATH):
          os.makedirs(FILE_PATH)
  
      # 返回的所有数据（响应头，响应体）
      res = requests.get(
          url="http://s.10010.com/hebei/mobilelist-0-0-0-0-0-0-0-0-29-0-0-p2/"
      )
  
      # 解码
      data = res.content.decode("utf-8")
  
      # 获取HTML格式的可解析对象
      soup_object = bs(data, "html.parser")
  
      # 逐步获取对象
      goods_object_list = soup_object.find_all(name="li", attrs={"class": "goodsLi"})
      for item in goods_object_list:
          name_object = item.find(name="p", attrs={"class": "mobileGoodsName"}).find(name="a").text.strip()
          price_object = item.find(name="p", attrs={"class": "evaluation"}).text.strip()
          price = re.findall("￥(\d+)", price_object)[0]
          comment_object = item.find(name="p", attrs={"class": "evalNum"}).find(name="a").text.strip()
          comment = re.findall("已有(\d+人)评价", comment_object)[0]
          img_url = item.find(name="img").attrs["data-original"]
          file_name = "{}.jpg".format(img_url[-18:-1])
          file_path = os.path.join(FILE_PATH, file_name)
          download(img_url, file_path)
          line = "{}|{}|{}|{}|{}\n".format(name_object, int(price), comment, img_url, file_path)
          with open("db.txt", mode="a", encoding="utf-8") as f:
              f.write(line)
  
  if __name__ == "__main__":
      run()
  ```
  
  
  
  